{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from dateutil.parser import parse\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set =  'feature_set_2_normalised'\n",
    "X_train = pd.read_csv( F'./data/{feature_set}/X_train_full.csv')\n",
    "y_train = pd.read_csv( F'./data/{feature_set}/y_train.csv').values.ravel()\n",
    "\n",
    "X_val = pd.read_csv( F'./data/{feature_set}/X_valid_full.csv')\n",
    "y_val = pd.read_csv( F'./data/{feature_set}/y_valid.csv').values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train= X_train.to_numpy()\n",
    "# # y_train= y_train.to_numpy()\n",
    " \n",
    "# y_train= y_train.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val= X_val.to_numpy()\n",
    "# y_val= y_val.to_numpy()\n",
    "\n",
    "# y_val= y_val.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshu\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "tb_cls = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "\t\t\t\t\toptimizer_params=dict(lr=1e-3),\n",
    "\t\t\t\t\tscheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "\t\t\t\t\tscheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "\t\t\t\t\tmask_type='entmax' # \"sparsemax\"\n",
    "\t\t\t\t\t)\n",
    "tb_cls.fit(X_train.values,y_train,\n",
    "\t\t\teval_set=[(X_train.values, y_train), (X_val.values, y_val)],\n",
    "\t\t\teval_name=['train', 'valid'],\n",
    "\t\t\teval_metric=['auc'],\n",
    "\t\t\tmax_epochs=1 , patience=100,\n",
    "\t\t\tbatch_size=28, drop_last=False)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
